version: "3.9"

services:
  agent_2:
    build:
      context: ../agents
      dockerfile: agent_2/Dockerfile
    environment:
      # Point this at sparky1 (backend host) from sparky2
      - WORLD_API_BASE=http://sparky1:8000
      - AGENT_TICK_SECONDS=2
      - DISPLAY_NAME=Tina
      - PERSONA_FILE=/app/personalities/tina.txt
      - USE_LANGGRAPH=1
      # OpenAI-compatible endpoint (set these in your environment or edit here)
      # - LLM_BASE_URL=http://sparky2:11434/v1
      # - LLM_API_KEY=local
      # - LLM_MODEL=llama3.1:70b
      - CHAT_PROBABILITY=0.45
      - CHAT_MIN_SECONDS=12
      - ADJACENT_CHAT_BOOST=3.0
      - RANDOM_MOVE_PROB=0.05
      - TOPIC_MIN_SECONDS=180
      - WORKSPACE_DIR=/app/workspace
    volumes:
      - ../agents/personalities:/app/personalities:ro
      - ../agents/workspaces/agent_2:/app/workspace
    restart: unless-stopped

